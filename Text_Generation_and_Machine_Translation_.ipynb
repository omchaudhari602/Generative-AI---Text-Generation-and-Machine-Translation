{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1.  What is Generative AI and what are its primary use cases across\n",
        "industries?\n",
        "\n",
        "ans :\n",
        "\n",
        "## What is Generative AI?\n",
        "Generative AI (Artificial Intelligence) is a branch of AI that focuses on creating new content such as text, images, audio, video, code, and synthetic data. It works by learning patterns from large datasets using deep learning models like Large Language Models (LLMs), Generative Adversarial Networks (GANs), and Diffusion Models. These models can generate realistic, creative, and context-aware outputs, enabling automation, creativity, and intelligent decision-making.\n",
        "\n",
        "---\n",
        "\n",
        "## Primary Use Cases Across Industries\n",
        "\n",
        "### 1. Healthcare\n",
        "- Medical report generation  \n",
        "- Drug discovery and molecule design  \n",
        "- Medical image analysis  \n",
        "- Virtual health assistants  \n",
        "\n",
        "### 2. Finance\n",
        "- Automated financial reports  \n",
        "- Fraud detection  \n",
        "- Risk analysis  \n",
        "- AI-powered chatbots  \n",
        "\n",
        "### 3. Education\n",
        "- Personalized learning content  \n",
        "- Virtual tutors  \n",
        "- Automated question generation  \n",
        "- Code explanation  \n",
        "\n",
        "### 4. Marketing & Advertising\n",
        "- Social media content generation  \n",
        "- Ad copywriting  \n",
        "- Product descriptions  \n",
        "- Creative design generation  \n",
        "\n",
        "### 5. Software Development\n",
        "- Code generation  \n",
        "- Debugging assistance  \n",
        "- Documentation writing  \n",
        "- Test case generation  \n",
        "\n",
        "### 6. Media & Entertainment\n",
        "- Story writing  \n",
        "- Music composition  \n",
        "- Video generation  \n",
        "- Game asset creation  \n",
        "\n",
        "### 7. E-commerce\n",
        "- Personalized product recommendations  \n",
        "- Customer service chatbots  \n",
        "- Product content generation  \n",
        "- Smart search  \n",
        "\n",
        "### 8. Manufacturing\n",
        "- Product design optimization  \n",
        "- Predictive maintenance  \n",
        "- Synthetic data generation  \n",
        "\n",
        "---\n",
        "\n",
        "## Conclusion\n",
        "Generative AI is transforming industries by increasing productivity, enhancing creativity, reducing manual effort, and enabling personalized experiences. As AI technology continues to evolve, its impact across industries will continue to grow.\n",
        "\n"
      ],
      "metadata": {
        "id": "JI92geNShhc4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Explain the role of probabilistic modeling in generative models. How do\n",
        "these models differ from discriminative models?\n",
        "\n",
        "ans:\n",
        "\n",
        "# Role of Probabilistic Modeling in Generative Models and Comparison with Discriminative Models\n",
        "\n",
        "## Role of Probabilistic Modeling in Generative Models\n",
        "Probabilistic modeling plays a key role in generative models by learning the **joint probability distribution** of the data and labels, denoted as **P(X, Y)** or simply **P(X)**. These models capture the underlying structure, patterns, and uncertainty present in the data.\n",
        "\n",
        "Using probabilistic techniques, generative models can:\n",
        "- Generate new and realistic data samples.\n",
        "- Handle uncertainty and noise in data.\n",
        "- Estimate missing data values.\n",
        "- Learn complex data distributions.\n",
        "\n",
        "Popular probabilistic generative models include **Gaussian Mixture Models (GMMs)**, **Hidden Markov Models (HMMs)**, **Variational Autoencoders (VAEs)**, and **Diffusion Models**.\n",
        "\n",
        "---\n",
        "\n",
        "## Difference Between Generative and Discriminative Models\n",
        "\n",
        "| Generative Models | Discriminative Models |\n",
        "|-------------------|------------------------|\n",
        "| Learn joint probability **P(X, Y)** | Learn conditional probability **P(Y | X)** |\n",
        "| Can generate new data samples | Cannot generate new data |\n",
        "| Model how data is produced | Model decision boundaries |\n",
        "| Handle missing data well | Require complete labeled data |\n",
        "| Examples: Naive Bayes, GMM, VAE, GAN | Examples: Logistic Regression, SVM, Neural Networks, Random Forest |\n",
        "\n",
        "---\n",
        "\n",
        "## Summary\n",
        "Generative models use probabilistic modeling to learn data distributions and generate new samples, while discriminative models focus on learning decision boundaries for accurate classification or prediction tasks.\n"
      ],
      "metadata": {
        "id": "_LWSSbI6iZNu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. What is the difference between Autoencoders and Variational\n",
        "Autoencoders (VAEs) in the context of text generation?\n",
        "\n",
        "ans:\n",
        "\n",
        "# Difference Between Autoencoders and Variational Autoencoders (VAEs) in Text Generation\n",
        "\n",
        "## Autoencoders (AEs)\n",
        "Autoencoders are neural network models designed to **compress input data into a low-dimensional latent representation** and then reconstruct the original data from it. They consist of an **encoder** and a **decoder**.\n",
        "\n",
        "In the context of text generation:\n",
        "- They learn deterministic latent representations.\n",
        "- Mainly used for **text compression, denoising, and feature extraction**.\n",
        "- They do **not model probability distributions explicitly**, so generating diverse and novel text is difficult.\n",
        "\n",
        "### Key Features:\n",
        "- Learn deterministic encoding.\n",
        "- Good for reconstruction tasks.\n",
        "- Limited creativity in text generation.\n",
        "\n",
        "---\n",
        "\n",
        "## Variational Autoencoders (VAEs)\n",
        "Variational Autoencoders are **probabilistic generative models** that learn a **distribution over the latent space** instead of fixed representations. They enable controlled and diverse text generation.\n",
        "\n",
        "In the context of text generation:\n",
        "- They learn probabilistic latent variables.\n",
        "- Can generate **new and diverse text samples**.\n",
        "- Provide smooth interpolation between different text samples.\n",
        "- Used in **creative writing, dialogue generation, and paraphrasing**.\n",
        "\n",
        "### Key Features:\n",
        "- Learn probabilistic latent distributions.\n",
        "- Support sampling and diversity.\n",
        "- Better for generative tasks.\n",
        "\n",
        "---\n",
        "\n",
        "## Key Differences\n",
        "\n",
        "| Autoencoders (AEs) | Variational Autoencoders (VAEs) |\n",
        "|--------------------|---------------------------------|\n",
        "| Deterministic latent space | Probabilistic latent space |\n",
        "| Focus on reconstruction | Focus on generation + reconstruction |\n",
        "| Cannot easily generate new samples | Can generate diverse new samples |\n",
        "| No explicit probability modeling | Explicit probability modeling |\n",
        "| Limited text generation | Strong text generation ability |\n",
        "\n",
        "---\n",
        "\n",
        "## Conclusion\n",
        "Autoencoders are mainly used for **representation learning and reconstruction**, while Variational Autoencoders are designed for **probabilistic modeling and creative text generation**, making VAEs more suitable for generative NLP applications.\n"
      ],
      "metadata": {
        "id": "DVM13o-nilJr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.  Describe the working of attention mechanisms in Neural Machine\n",
        "Translation (NMT). Why are they critical?\n",
        "\n",
        "ans:\n",
        "\n",
        "# Working of Attention Mechanisms in Neural Machine Translation (NMT) and Their Importance\n",
        "\n",
        "## What is Attention Mechanism?\n",
        "The attention mechanism is a technique used in Neural Machine Translation (NMT) that allows the model to **focus on the most relevant parts of the source sentence while generating each word of the target sentence**. Instead of encoding the entire input sentence into a single fixed-length vector, attention dynamically assigns importance (weights) to different input words.\n",
        "\n",
        "---\n",
        "\n",
        "## Working of Attention Mechanism in NMT\n",
        "\n",
        "1. **Encoder Processing**  \n",
        "   The encoder converts each input word into a hidden state, producing a sequence of hidden representations.\n",
        "\n",
        "2. **Decoder Step with Attention**  \n",
        "   At each decoding step, the decoder calculates attention weights over all encoder hidden states.\n",
        "\n",
        "3. **Alignment Score Calculation**  \n",
        "   The model computes alignment scores that indicate how relevant each input word is to generating the current output word.\n",
        "\n",
        "4. **Context Vector Creation**  \n",
        "   A weighted sum of encoder hidden states is calculated using attention weights to form a context vector.\n",
        "\n",
        "5. **Word Prediction**  \n",
        "   The decoder uses this context vector along with its current hidden state to predict the next word.\n",
        "\n",
        "---\n",
        "\n",
        "## Why Attention Mechanisms Are Critical?\n",
        "\n",
        "- **Handles long sentences effectively** by avoiding information bottlenecks.\n",
        "- **Improves translation accuracy** by focusing on relevant words.\n",
        "- **Provides dynamic word alignment** between source and target languages.\n",
        "- **Enhances fluency and grammatical correctness**.\n",
        "- **Enables parallel processing** in Transformer models.\n",
        "\n",
        "---\n",
        "\n",
        "## Summary\n",
        "Attention mechanisms allow NMT systems to dynamically focus on relevant parts of the input sentence during translation, leading to **better accuracy, efficiency, and performance**, especially for long and complex sentences.\n"
      ],
      "metadata": {
        "id": "Efbx70dBirmb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5.  What ethical considerations must be addressed when using generative AI\n",
        "for creative content such as poetry or storytelling?\n",
        "\n",
        "ans:\n",
        "\n",
        "# Ethical Considerations in Using Generative AI for Creative Content\n",
        "\n",
        "## Introduction\n",
        "Generative AI is increasingly used to create creative content such as poetry, stories, scripts, and artwork. While it offers powerful creative capabilities, it also raises important ethical concerns that must be addressed to ensure responsible and fair use.\n",
        "\n",
        "---\n",
        "\n",
        "## Key Ethical Considerations\n",
        "\n",
        "### 1. Originality and Plagiarism\n",
        "- AI models are trained on large datasets, which may include copyrighted works.\n",
        "- Generated content may unintentionally resemble existing creations.\n",
        "- Ensuring originality and avoiding plagiarism is essential.\n",
        "\n",
        "### 2. Copyright and Intellectual Property\n",
        "- Ownership of AI-generated content is unclear in many legal systems.\n",
        "- Using copyrighted training data without consent raises legal and ethical issues.\n",
        "\n",
        "### 3. Authorship and Attribution\n",
        "- It is important to clearly disclose when content is AI-generated.\n",
        "- Proper credit should be given to human contributors when involved.\n",
        "\n",
        "### 4. Bias and Fair Representation\n",
        "- AI models can reflect biases present in training data.\n",
        "- This may lead to unfair stereotypes or harmful narratives.\n",
        "\n",
        "### 5. Misinformation and Manipulation\n",
        "- AI-generated stories can be used to spread false information.\n",
        "- Safeguards are needed to prevent misuse.\n",
        "\n",
        "### 6. Cultural Sensitivity\n",
        "- AI-generated content must respect cultural, religious, and social values.\n",
        "- Avoid offensive or inappropriate material.\n",
        "\n",
        "---\n",
        "\n",
        "## Conclusion\n",
        "Ethical use of generative AI in creative content requires maintaining originality, fairness, transparency, and responsibility. Addressing these ethical challenges ensures that AI creativity benefits society without causing harm.\n"
      ],
      "metadata": {
        "id": "zTNyHYRzi1Sj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Use the following small text dataset to train a simple Variational\n",
        "Autoencoder (VAE) for text reconstruction:\n",
        "[\"The sky is blue\", \"The sun is bright\", \"The grass is green\",\n",
        "\"The night is dark\", \"The stars are shining\"]\n",
        "1. Preprocess the data (tokenize and pad the sequences).\n",
        "2. Build a basic VAE model for text reconstruction.\n",
        "3. Train the model and show how it reconstructs or generates similar sentences.\n",
        "Include your code, explanation, and sample outputs.\n",
        "\n",
        "\n",
        "ans:\n",
        "\n",
        "Variational Autoencoder (VAE) for Simple Text Reconstruction\n",
        "\n",
        "We will:\n",
        "\n",
        "1. Preprocess the dataset\n",
        "\n",
        "2. Build a basic VAE model\n",
        "\n",
        "3. Train the model\n",
        "\n",
        "4. Reconstruct and generate similar sentences"
      ],
      "metadata": {
        "id": "d9fH_U1Ui9a-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras import layers, models, backend as K\n",
        "\n",
        "# Dataset\n",
        "sentences = [\n",
        "    \"The sky is blue\",\n",
        "    \"The sun is bright\",\n",
        "    \"The grass is green\",\n",
        "    \"The night is dark\",\n",
        "    \"The stars are shining\"\n",
        "]\n",
        "\n",
        "# Tokenization\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(sentences)\n",
        "\n",
        "sequences = tokenizer.texts_to_sequences(sentences)\n",
        "word_index = tokenizer.word_index\n",
        "vocab_size = len(word_index) + 1\n",
        "\n",
        "# Padding\n",
        "max_len = max(len(seq) for seq in sequences)\n",
        "padded = pad_sequences(sequences, maxlen=max_len, padding='post')\n",
        "\n",
        "print(\"Word Index:\", word_index)\n",
        "print(\"Padded Sequences:\\n\", padded)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OyImhvkzjOVB",
        "outputId": "7c6504d6-7d21-4dca-be81-3a8b84ad3ff9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word Index: {'the': 1, 'is': 2, 'sky': 3, 'blue': 4, 'sun': 5, 'bright': 6, 'grass': 7, 'green': 8, 'night': 9, 'dark': 10, 'stars': 11, 'are': 12, 'shining': 13}\n",
            "Padded Sequences:\n",
            " [[ 1  3  2  4]\n",
            " [ 1  5  2  6]\n",
            " [ 1  7  2  8]\n",
            " [ 1  9  2 10]\n",
            " [ 1 11 12 13]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2 — Build Variational Autoencoder (VAE)  "
      ],
      "metadata": {
        "id": "O06xfqT2jUDQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import keras.ops as ops\n",
        "\n",
        "embedding_dim = 16\n",
        "latent_dim = 8\n",
        "\n",
        "# Encoder\n",
        "inputs = layers.Input(shape=(max_len,))\n",
        "x = layers.Embedding(vocab_size, embedding_dim)(inputs)\n",
        "x = layers.LSTM(32)(x)\n",
        "\n",
        "z_mean = layers.Dense(latent_dim)(x)\n",
        "z_log_var = layers.Dense(latent_dim)(x)\n",
        "\n",
        "def sampling(args):\n",
        "    z_mean, z_log_var = args\n",
        "    epsilon = K.random_normal(shape=(ops.shape(z_mean)[0], latent_dim))\n",
        "    return z_mean + ops.exp(0.5 * z_log_var) * epsilon\n",
        "\n",
        "z = layers.Lambda(sampling)([z_mean, z_log_var])\n",
        "\n",
        "# Decoder\n",
        "decoder_input = layers.RepeatVector(max_len)(z)\n",
        "decoder_lstm = layers.LSTM(32, return_sequences=True)(decoder_input)\n",
        "outputs = layers.TimeDistributed(layers.Dense(vocab_size, activation='softmax'))(decoder_lstm)\n",
        "\n",
        "vae = models.Model(inputs, outputs)\n",
        "\n",
        "# Custom Layer for expand_dims\n",
        "class ExpandDimsLayer(layers.Layer):\n",
        "    def __init__(self, axis=-1, **kwargs):\n",
        "        super(ExpandDimsLayer, self).__init__(**kwargs)\n",
        "        self.axis = axis\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return ops.expand_dims(inputs, axis=self.axis)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super(ExpandDimsLayer, self).get_config()\n",
        "        config.update({\"axis\": self.axis})\n",
        "        return config\n",
        "\n",
        "# Loss Function\n",
        "# Reshape inputs to (batch_size, max_len, 1) for sparse_categorical_crossentropy\n",
        "inputs_reshaped = ExpandDimsLayer(axis=-1)(inputs)\n",
        "recon_loss = tf.keras.losses.sparse_categorical_crossentropy(y_true=inputs_reshaped, y_pred=outputs)\n",
        "recon_loss = ops.mean(recon_loss)\n",
        "\n",
        "kl_loss = -0.5 * ops.mean(1 + z_log_var - ops.square(z_mean) - ops.exp(z_log_var))\n",
        "\n",
        "vae_loss = recon_loss + kl_loss\n",
        "vae.add_loss(vae_loss)\n",
        "\n",
        "vae.compile(optimizer='adam')\n",
        "vae.summary()"
      ],
      "metadata": {
        "id": "K47KGHgBmukN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3 — Train the Model"
      ],
      "metadata": {
        "id": "0M-8IndVjY-M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vae.fit(padded, padded, epochs=300, batch_size=2, verbose=1)\n"
      ],
      "metadata": {
        "id": "7oG9MstgjWQ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "step 4 Text Reconstruction"
      ],
      "metadata": {
        "id": "mlTslrZSjb13"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_sequence(seq):\n",
        "    reverse_index = {v:k for k,v in tokenizer.word_index.items()}\n",
        "    return \" \".join([reverse_index.get(i, \"\") for i in seq if i != 0])\n",
        "\n",
        "pred = vae.predict(padded)\n",
        "pred_ids = np.argmax(pred, axis=-1)\n",
        "\n",
        "for i in range(len(sentences)):\n",
        "    print(\"Original     :\", sentences[i])\n",
        "    print(\"Reconstructed:\", decode_sequence(pred_ids[i]))\n",
        "    print()\n"
      ],
      "metadata": {
        "id": "Vah2Pzw6jeYh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Use a pre-trained GPT model (like GPT-2 or GPT-3) to translate a short\n",
        "English paragraph into French and German. Provide the original and translated text.\n",
        "\n",
        "ans:\n",
        "\n"
      ],
      "metadata": {
        "id": "CmuIh8XWmvyQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. Implement a simple attention-based encoder-decoder model for\n",
        "English-to-Spanish translation using Tensorflow or PyTorch.\n"
      ],
      "metadata": {
        "id": "dnlQoYyYnEKQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade transformers sentencepiece -q\n",
        "\n",
        "from transformers import pipeline\n",
        "\n",
        "# Load translation models\n",
        "translator_en_fr = pipeline(\"translation_en_to_fr\", model=\"Helsinki-NLP/opus-mt-en-fr\")\n",
        "translator_en_de = pipeline(\"translation_en_to_de\", model=\"Helsinki-NLP/opus-mt-en-de\")\n",
        "\n",
        "# English input paragraph\n",
        "text = \"Artificial Intelligence is transforming the world by enabling machines to think, learn, and solve complex problems efficiently.\"\n",
        "\n",
        "# Perform translations\n",
        "french_translation = translator_en_fr(text)[0]['translation_text']\n",
        "german_translation = translator_en_de(text)[0]['translation_text']\n",
        "\n",
        "# Display results\n",
        "print(\"Original English Text:\\n\", text)\n",
        "print(\"\\nFrench Translation:\\n\", french_translation)\n",
        "print(\"\\nGerman Translation:\\n\", german_translation)"
      ],
      "metadata": {
        "id": "t9AhAKkUnzLM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple Attention-based Encoder–Decoder Model for English → Spanish Translation\n",
        "# Single-cell Colab implementation\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras import layers, Model\n",
        "\n",
        "# -----------------------------\n",
        "# 1. Small Dataset\n",
        "# -----------------------------\n",
        "eng_sentences = [\n",
        "    \"hello\", \"how are you\", \"i love you\", \"good morning\", \"thank you\", \"good night\"\n",
        "]\n",
        "\n",
        "spa_sentences = [\n",
        "    \"hola\", \"como estas\", \"te amo\", \"buenos dias\", \"gracias\", \"buenas noches\"\n",
        "]\n",
        "\n",
        "# -----------------------------\n",
        "# 2. Tokenization\n",
        "# -----------------------------\n",
        "eng_tokenizer = Tokenizer()\n",
        "spa_tokenizer = Tokenizer()\n",
        "\n",
        "eng_tokenizer.fit_on_texts(eng_sentences)\n",
        "spa_tokenizer.fit_on_texts(spa_sentences)\n",
        "\n",
        "eng_seq = eng_tokenizer.texts_to_sequences(eng_sentences)\n",
        "spa_seq = spa_tokenizer.texts_to_sequences(spa_sentences)\n",
        "\n",
        "max_len = max(max(len(s) for s in eng_seq), max(len(s) for s in spa_seq))\n",
        "\n",
        "eng_pad = pad_sequences(eng_seq, maxlen=max_len, padding='post')\n",
        "spa_pad = pad_sequences(spa_seq, maxlen=max_len, padding='post')\n",
        "\n",
        "eng_vocab = len(eng_tokenizer.word_index) + 1\n",
        "spa_vocab = len(spa_tokenizer.word_index) + 1\n",
        "\n",
        "# -----------------------------\n",
        "# 3. Model Parameters\n",
        "# -----------------------------\n",
        "embedding_dim = 64\n",
        "units = 128\n",
        "batch_size = 2\n",
        "epochs = 300\n",
        "\n",
        "# -----------------------------\n",
        "# 4. Encoder\n",
        "# -----------------------------\n",
        "encoder_inputs = layers.Input(shape=(max_len,))\n",
        "enc_emb = layers.Embedding(eng_vocab, embedding_dim)(encoder_inputs)\n",
        "encoder_outputs, state_h, state_c = layers.LSTM(units, return_sequences=True, return_state=True)(enc_emb)\n",
        "\n",
        "# -----------------------------\n",
        "# 5. Attention Layer\n",
        "# -----------------------------\n",
        "attention = layers.Attention()\n",
        "context_vector = attention([encoder_outputs, encoder_outputs])\n",
        "\n",
        "# -----------------------------\n",
        "# 6. Decoder\n",
        "# -----------------------------\n",
        "decoder_inputs = layers.Input(shape=(max_len,))\n",
        "dec_emb = layers.Embedding(spa_vocab, embedding_dim)(decoder_inputs)\n",
        "decoder_lstm = layers.LSTM(units, return_sequences=True)\n",
        "decoder_outputs = decoder_lstm(dec_emb, initial_state=[state_h, state_c])\n",
        "\n",
        "concat = layers.Concatenate()([decoder_outputs, context_vector])\n",
        "outputs = layers.TimeDistributed(layers.Dense(spa_vocab, activation=\"softmax\"))(concat)\n",
        "\n",
        "model = Model([encoder_inputs, decoder_inputs], outputs)\n",
        "\n",
        "# -----------------------------\n",
        "# 7. Compile Model\n",
        "# -----------------------------\n",
        "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "# -----------------------------\n",
        "# 8. Train Model\n",
        "# -----------------------------\n",
        "model.fit([eng_pad, spa_pad], spa_pad, batch_size=batch_size, epochs=epochs, verbose=1)\n",
        "\n",
        "# -----------------------------\n",
        "# 9. Translation Function\n",
        "# -----------------------------\n",
        "reverse_spa_index = {v:k for k,v in spa_tokenizer.word_index.items()}\n",
        "\n",
        "def translate(sentence):\n",
        "    seq = eng_tokenizer.texts_to_sequences([sentence])\n",
        "    pad = pad_sequences(seq, maxlen=max_len, padding='post')\n",
        "    pred = model.predict([pad, pad])\n",
        "    ids = np.argmax(pred[0], axis=-1)\n",
        "    return \" \".join([reverse_spa_index.get(i,\"\") for i in ids if i != 0])\n",
        "\n",
        "# -----------------------------\n",
        "# 10. Testing\n",
        "# -----------------------------\n",
        "tests = [\"hello\", \"good morning\", \"thank you\", \"i love you\"]\n",
        "\n",
        "for t in tests:\n",
        "    print(f\"English : {t}\")\n",
        "    print(f\"Spanish : {translate(t)}\")\n",
        "    print(\"-\"*40)\n"
      ],
      "metadata": {
        "id": "EUFCfk0XnBfY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "9.  Use the following short poetry dataset to simulate poem generation with a\n",
        "pre-trained GPT model:\n",
        "[\"Roses are red, violets are blue,\",\n",
        "\"Sugar is sweet, and so are you.\",\n",
        "\"The moon glows bright in silent skies,\",\n",
        "\"A bird sings where the soft wind sighs.\"]\n",
        "Using this dataset as a reference for poetic structure and language, generate a new 2-4\n",
        "line poem using a pre-trained GPT model (such as GPT-2). You may simulate\n",
        "fine-tuning by prompting the model with similar poetic patterns.\n",
        "Include your code, the prompt used, and the generated poem in your answer"
      ],
      "metadata": {
        "id": "iJqOMUKQnadX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Poem Generation using Pre-trained GPT-2 (Single Cell Colab Code)\n",
        "\n",
        "!pip install transformers -q\n",
        "\n",
        "from transformers import pipeline, set_seed\n",
        "\n",
        "# Load GPT-2 text generation pipeline\n",
        "generator = pipeline(\"text-generation\", model=\"gpt2\")\n",
        "\n",
        "# Fix randomness for reproducibility\n",
        "set_seed(42)\n",
        "\n",
        "# Poetry dataset (used as reference)\n",
        "dataset = [\n",
        "    \"Roses are red, violets are blue,\",\n",
        "    \"Sugar is sweet, and so are you.\",\n",
        "    \"The moon glows bright in silent skies,\",\n",
        "    \"A bird sings where the soft wind sighs.\"\n",
        "]\n",
        "\n",
        "# Prompt simulating poetic fine-tuning\n",
        "prompt = \"\"\"Roses are red, violets are blue,\n",
        "Sugar is sweet, and so are you.\n",
        "The moon glows bright in silent skies,\n",
        "A bird sings where the soft wind sighs.\n",
        "Now write a new short poem in similar style:\"\"\"\n",
        "\n",
        "# Generate poem\n",
        "output = generator(\n",
        "    prompt,\n",
        "    max_length=70,\n",
        "    num_return_sequences=1,\n",
        "    temperature=0.8,\n",
        "    top_p=0.95\n",
        ")[0][\"generated_text\"]\n",
        "\n",
        "# Display results\n",
        "print(\"Prompt Used:\\n\", prompt)\n",
        "print(\"\\nGenerated Poem:\\n\", output.replace(prompt, \"\"))\n"
      ],
      "metadata": {
        "id": "VvdQ3_srnigH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "10.  Imagine you are building a creative writing assistant for a publishing\n",
        "company. The assistant should generate story plots and character descriptions using\n",
        "Generative AI. Describe how you would design the system, including model selection,\n",
        "training data, bias mitigation, and evaluation methods. Explain the real-world challenges\n",
        "you might face.\n",
        "\n",
        "ans:\n",
        "\n",
        "# Designing a Creative Writing Assistant Using Generative AI\n",
        "\n",
        "## Introduction\n",
        "A creative writing assistant for a publishing company aims to generate engaging **story plots and character descriptions** using Generative AI. The system must produce **creative, coherent, diverse, and ethically responsible content** while supporting human writers in brainstorming and content creation.\n",
        "\n",
        "---\n",
        "\n",
        "## System Design Overview\n",
        "\n",
        "### 1. Model Selection\n",
        "- Use **large pre-trained language models** such as **GPT-4, GPT-3.5, LLaMA, or Mistral**.\n",
        "- Fine-tune the model for **creative writing tasks**.\n",
        "- For high performance: use **Transformer-based architectures**.\n",
        "- Optional: Combine **text-to-image models** (e.g., Stable Diffusion) for character visualization.\n",
        "\n",
        "---\n",
        "\n",
        "### 2. Training Data\n",
        "- High-quality **fiction books, novels, short stories, scripts, and screenplays**.\n",
        "- Genre-specific datasets: fantasy, romance, thriller, sci-fi, mystery, drama.\n",
        "- Public domain literature (e.g., Project Gutenberg).\n",
        "- Human-written story outlines and character profiles.\n",
        "\n",
        "**Preprocessing steps:**\n",
        "- Remove duplicates, copyrighted data, and sensitive content.\n",
        "- Normalize text and remove bias-related patterns.\n",
        "- Tag data with genres, emotions, and writing style.\n",
        "\n",
        "---\n",
        "\n",
        "### 3. System Architecture\n",
        "\n",
        "**User Prompt → NLP Interface → Generative Model → Post-Processing → Final Output**\n",
        "\n",
        "Key Components:\n",
        "- Prompt engineering layer  \n",
        "- Story plot generator  \n",
        "- Character description generator  \n",
        "- Style controller (tone, genre, mood)  \n",
        "- Content moderation filter  \n",
        "\n",
        "---\n",
        "\n",
        "### 4. Bias Mitigation Strategies\n",
        "- Use **balanced and diverse datasets** across cultures, genders, and backgrounds.\n",
        "- Apply **bias detection algorithms** and human audits.\n",
        "- Use **reinforcement learning with human feedback (RLHF)**.\n",
        "- Add **ethical filters** to prevent stereotypes and offensive content.\n",
        "\n",
        "---\n",
        "\n",
        "### 5. Evaluation Methods\n",
        "\n",
        "#### Automatic Metrics:\n",
        "- **Perplexity** → fluency\n",
        "- **BLEU / ROUGE** → coherence\n",
        "- **Diversity metrics** → creativity\n",
        "- **Toxicity detection scores**\n",
        "\n",
        "#### Human Evaluation:\n",
        "- Creativity\n",
        "- Emotional impact\n",
        "- Character depth\n",
        "- Plot originality\n",
        "- Readability\n",
        "\n",
        "#### A/B Testing:\n",
        "- Compare AI-generated vs human-assisted writing quality.\n",
        "\n",
        "---\n",
        "\n",
        "## Real-World Challenges\n",
        "\n",
        "### 1. Creativity vs Originality\n",
        "- Avoid plagiarism while maintaining creativity.\n",
        "\n",
        "### 2. Bias and Fair Representation\n",
        "- Prevent cultural, gender, and social biases.\n",
        "\n",
        "### 3. Ethical and Legal Concerns\n",
        "- Copyright compliance  \n",
        "- Ownership of AI-generated stories  \n",
        "\n",
        "### 4. Long-Context Coherence\n",
        "- Maintaining story consistency across long narratives.\n",
        "\n",
        "### 5. Cost and Computation\n",
        "- High training and inference costs.\n",
        "\n",
        "### 6. Human-AI Collaboration\n",
        "- Ensuring AI assists rather than replaces writers.\n",
        "\n",
        "---\n",
        "\n",
        "## Conclusion\n",
        "A well-designed creative writing assistant using Generative AI can significantly enhance storytelling by generating high-quality story plots and character descriptions. Addressing **bias, ethics, creativity, and evaluation challenges** is essential to ensure responsible and effective real-world deployment.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "9FkIiVAHnknr"
      }
    }
  ]
}